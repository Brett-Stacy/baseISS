---
title: "Booting Hauls Implications"
author: "Brett Stacy"
date: "2024-06-24"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

# Why do we boot hauls instead of just boot samples from every haul?

In surveyISS and the associated literature, hauls are resampled for a number of iterations. For each resampled haul, the length composition from that haul is resampled once. Howevewr, because the hauls are resampled with equal probability, I propose that as the iterations approach large numbers, this procedure is equivalent to resampling each of the samples an equal number of times. The number of times would be approximately equal to iterations/#hauls. 


To test this, I will create an idealized situation with few hauls that have large differences in sample sizes. I will then resample by hauls and resample by samples and compare the difference in sample size as the number of iterations grows. If they converge, then I am right. 

```{r}
iters = 10

DT = data.table(hauls = letters[1:3], sample_size = c(1, 100, 1000))

booted_hauls = purrr::map(1:iters, ~sample(DT$hauls, replace = T))


# associated sample sizes from one set of resampled hauls 
# booted_hauls[[1]] %>%
  # purrr::map_vec(.f=function(x) DT[hauls == x, sample_size])

# make the above into a function and add sum the sample size
total.sample.size = function(og.data, resample){
  resample %>%
    purrr::map_vec(.f = function(x) og.data[hauls == x, sample_size]) %>%
    sum() -> temp
    return(temp)
}
# total.sample.size(DT, booted_hauls[[1]])


# perform the function over all booted hauls. 
booted_hauls %>%
  purrr::map_vec(.f = function(x) total.sample.size(DT, x)) %>%
  sum() -> ss_boot_hauls

ss_boot_hauls



## Compare to just multiplying the sample sizes by the number of times their associated hauls were resampled
# count how many "a"s, "b"s, and "c"s there are in the resampled hauls
DT[, count_resampled_hauls := table(unlist(booted_hauls))]

DT[, sum(sample_size*count_resampled_hauls)]

DT

```

Conclusion: These numbers are exactly the same. This is because both methods are doing the same thing, just in a different way. The first one sums first by each resampled iteration, then sums over all iterations. The second sums over all iterations, then sums by the frequency of the haul in the resample.


## Compare to just multiplying sample size by number of bootstrap iterations. 

```{r}

iters = 1000

## First calculate the sum of sample sizes from the bootstrap, using method 2 above (faster)
DT = data.table(hauls = letters[1:3], sample_size = c(1, 100, 1000))
booted_hauls = purrr::map(1:iters, ~sample(DT$hauls, replace = T))
# count how many "a"s, "b"s, and "c"s there are in the resampled hauls
DT[, count_resampled_hauls := table(unlist(booted_hauls))]
DT[, sum(sample_size*count_resampled_hauls)]


## Second simply multiply each sample size by iters and sum
sum(DT[, sample_size]*iters)


## Subtract the two
DT[, sum(sample_size*count_resampled_hauls)] - sum(DT[, sample_size]*iters)

```


## Do it a bunch of times and boxplot the result

```{r}
global.iters = 1000

DT = data.table(hauls = letters[1:3], sample_size = c(1, 100, 1000))

diff_methods = function(x){
  iters = 1000
  ## First calculate the sum of sample sizes from the bootstrap, using method 2 above (faster)
  
  booted_hauls = purrr::map(1:iters, ~sample(x$hauls, replace = T))
  # count how many "a"s, "b"s, and "c"s there are in the resampled hauls
  x[, count_resampled_hauls := table(unlist(booted_hauls))]
  method1 = x[, sum(sample_size*count_resampled_hauls)]
  ## Second simply multiply each sample size by iters and sum
  method2 = sum(x[, sample_size]*iters)
  ## Subtract the two
  return((method1 - method2)/method1)
}


purrr::map_vec(1:global.iters, ~diff_methods(DT)) -> methods_error

boxplot(methods_error)



```


Conclusion: The error between the two methods is zero, indicating there is no difference between methods and they provide the same information. The total sample size generated by bootstrapping for many iterations is equivalent to multiplying the sample sizes by the number of iterations and adding them up. 

As suspected, sampling a vector where each element has the equal probability of being selected will result in the same number of each element being resampled. 

This means that, for surveyISS purposes, each length composisiton sample could simply be resampled 500 times and provide the same answer as resampling the hauls 500 times. 














